{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat Analysis\n",
    "\n",
    "You can use your WhatsApp data for many data science tasks like sentiment analysis, keyword extraction, named entity recognition, text analysis and several other natural language processing tasks. It also depends on who you are analyzing your WhatsApp messages with because you can find a lot of information from your WhatsApp messages which can also help you to solve business problems.\n",
    "\n",
    "Before starting with the task of WhatsApp Chat analysis with Python you need to extract your WhatsApp data from your smartphone which is a very easy task. To extract your WhatsApp chats, just open any chat with a person or a group and follow the steps mentioned below:\n",
    "\n",
    "If you are having an iPhone then tap on the Contact Name or the Group Name. In case you are having an Android smartphone then tap on the 3 dots above.\n",
    "- Then scroll to the bottom and top on Export Chat.\n",
    "- Then select without media for simplicity if it asks you whether you want your chats with or without media.\n",
    "- Then email this chat to yourself and download it to your system.\n",
    "So this is how you can easily get your WhatsApp chats with any person or a group for the task of WhatsApp chat analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFFiKCyEbik_"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# % matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQG8dOgab1e8",
    "outputId": "7db8ab7c-24b5-4196-df43-082a86a039c3"
   },
   "outputs": [],
   "source": [
    "def startsWithDateAndTime(s):\n",
    "    pattern = r\"[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}\" #, r\"([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -\" # [\\d]{1,2}/[\\d]{1,2}/[\\d]{4} ^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+)\n",
    "    result = re.findall(pattern, s)\n",
    "    print(\"result :\", result)\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7_dc8C1QMsv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOFaqY7dcoL6"
   },
   "outputs": [],
   "source": [
    "def FindAuthor(s):\n",
    "    s=s.split(\":\")\n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uwosheoc26g"
   },
   "outputs": [],
   "source": [
    "def getDataPoint(line):  \n",
    "    splitLine = line.split(' - ') \n",
    "    dateTime = splitLine[0]\n",
    "    date, time = dateTime.split(', ') \n",
    "    message = ' '.join(splitLine[1:])\n",
    "    if FindAuthor(message):\n",
    "        splitMessage = message.split(': ') \n",
    "        author = splitMessage[0] \n",
    "        message = ' '.join(splitMessage[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XmV5atzc_Kc",
    "outputId": "ea3080d4-e3d6-4cc5-b176-b720975f20c2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "parsedData = [] # List to keep track of data so it can be used by a Pandas dataframe\n",
    "conversation = \"/WhatsApp.txt\" # path for the whatsapp text file\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "\n",
    "    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n",
    "    print(\"fp.readline() : \\n\", fp.readline())\n",
    "    messageBuffer = [] \n",
    "    print(\"messageBuffer : \\n\", messageBuffer)\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip() \n",
    "        print(\"line: \\n\", line)\n",
    "        if startsWithDateAndTime(line):\n",
    "            print(\"startsWithDateAndTime : \\n\", startsWithDateAndTime)\n",
    "            if len(messageBuffer) > 0:\n",
    "            parsedData.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear() \n",
    "            date, time, author, message = getDataPoint(line) \n",
    "            messageBuffer.append(message)\n",
    "\n",
    "        else:\n",
    "            messageBuffer.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8pMZBYJeaI-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eHW9i3hUeccy",
    "outputId": "a102a7ef-ebac-4b04-fc85-26f86bb6a0ea"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmaAjBxkgNfv",
    "outputId": "f8674ae4-25ca-4d52-8ce1-2a04b92091b1"
   },
   "outputs": [],
   "source": [
    "df.Author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYrQD7LIl87z",
    "outputId": "8f063673-ee81-4e9d-ff5e-b045ef0c41a3"
   },
   "outputs": [],
   "source": [
    "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
    "# print(media_messages)\n",
    "\n",
    "def split_count(text):\n",
    "    data = re.findall(r'\\X', text)\n",
    "    emoji_list = []\n",
    "\n",
    "    for word in data:\n",
    "    emojis = emoji.distinct_emoji_list(word)\n",
    "    emoji_list.extend([emoji.demojize(is_emoji) for is_emoji in emojis])\n",
    "\n",
    "    # emoji_list = []\n",
    "    # for word in data:\n",
    "    #   if any(char in emoji.distinct_emoji_list for char in word):\n",
    "    #     emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "# print(emojis)\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "# print(\"Data science Community\")\n",
    "# print(\"Messages:\",total_messages)\n",
    "print(\"Media:\",media_messages)\n",
    "print(\"Emojis:\",emojis)\n",
    "print(\"Links:\",links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cF0VfDWvm-Cx",
    "outputId": "b1e128d7-704b-4855-aad1-d25bcb1f2182"
   },
   "outputs": [],
   "source": [
    "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
    "messages_df = df.drop(media_messages_df.index)\n",
    "messages_df.info()\n",
    "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "messages_df[\"MessageCount\"]=1\n",
    "\n",
    "l = ['a','b','c'] # list of the authors name in the group\n",
    "\n",
    "for i in range(len(l)):\n",
    "    # Filtering out messages of particular user\n",
    "    req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
    "    # req_df will contain messages of only one particular user\n",
    "    print('\\n')\n",
    "    print(f'Stats of {l[i]} -')\n",
    "    # shape will print number of rows which indirectly means the number of messages\n",
    "    print('Messages Sent', req_df.shape[0])\n",
    "    #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "    words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
    "    print('Words per message', words_per_message)\n",
    "    #media conists of media messages\n",
    "    media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
    "    print('Media Messages Sent', media)\n",
    "    # emojis conists of total emojis\n",
    "    emojis = sum(req_df['emoji'].str.len())\n",
    "    print('Emojis Sent', emojis)\n",
    "    #links consist of total links\n",
    "    links = sum(req_df[\"urlcount\"])   \n",
    "    print('Links Sent', links)\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-BBk1Hym-S8",
    "outputId": "9353a11f-a8f9-49e3-bde2-3766db01d915"
   },
   "outputs": [],
   "source": [
    "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
    "emoji_dict = dict(Counter(total_emojis_list))\n",
    "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in emoji_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "2KocJxRqsOY2",
    "outputId": "fcaefc9d-7888-4bc3-e7cd-dd4dbb572b16"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in messages_df.Message)\n",
    "print (\"There are {} words in all the messages.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0HI2ZpVYsOaJ",
    "outputId": "7a90df15-ae10-4b5c-dba7-cc291a6a0ac9"
   },
   "outputs": [],
   "source": [
    "l = ['a','b','c']\n",
    "for i in range(len(l)):\n",
    "    dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
    "    text = \" \".join(review for review in dummy_df.Message)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    #Generate a word cloud image\n",
    "    print('Author name',l[i])\n",
    "    wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "    #Display the generated image   \n",
    "    plt.figure( figsize=(10,5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
